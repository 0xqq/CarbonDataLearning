我今天演讲的主要内容，首先我会讲一下用例和挑战，接着我会讲一下统一的数据分析，在随后我会讲carbon data的技术和解决方案，以及我们为什么要对carbon data进行开源，和carbon data的线路图是怎样的？实际我们有太多的数据，比如电信运营商他们有那么多用户，这些用户随时都在产生数据，比如小区功率信号强度，基站的负载数据等等。另外还有很多企业，包括银行，他们都会在内部产生太多的数据，这些数据就需要保存。数据保存在数据仓库中，这些数据到底如何去利用，操纵之后要看一下如何去使用这个数据，这是一个大问题。各国的法规，这些数据需要进行非常好的维护，因为大家都知道在这个新的时代，数据就是新的石油有很多价值，但是这个价值到底该如何去挖掘，还需要我们进一步开发出新的方案来。可以用于报表以及仪表盘等等功能，可以帮助你来识别出业务中有哪些需要改进的方向，你当前的业务模式是不是合适在未来可能出现什么样的趋势，我们还可以用这些数据来分析交通状况，分析某些公司的车队或者团队，另外还可以用来做智慧校园等等。数据分析需要我们借助新的手段，比如现在我们有机器学习在此方面的研究是很多的，实际上在方方面面都有很大的作用，我们可以进行数据分析，从而实现欺诈检测。对于家居可以实现自动化，我们通过交通分析，可以让城市变得更智能。我们对社交媒体上的数据进行分析，可以预测用户行为，从而使得广告的投放更精准。我们也可以分析用户的行为和用户的偏好，使得产品在设计和开发的时候更具有针对性。我刚才说了这么多的用例，都需要进行深入的讨论，我们知道数据的量这么大，我们该如何去存储？如何更好的分析，从而获取有价值的信息，这就需要我们去开发新的方案来。可能一张数据表里面就涵盖了几十亿条数据，这些数据有非常多的细节，他们可能有非常多的维度，几百个维度，数据本身基数就非常大，而每一条数据可能有其独特性，而数据产生的速度也非常快，有时候我们以非常高速的速率，甚至是实时的方式来产生数据。讲的数据可以用于报表功能，也可以帮我们实现很多仪表盘的功能，这就需要我们对数据进行非常全面的扫描，对于扫描我们或许要实现分布式的处理，这样扫描可以在有限的时间内快速的完成，或者我们也可以进行搜索，在数据中发现一些特定的事物或者是规律，这就要求我们快速的找到数据，并且将其检索出来。我们也可以做机器学习和深度学习的模型，我们需要从数据样本中来学习。在数据学习过程中需要不停的去修改，随后对模式在进行运行。这样我们可以看到我们当前的模式和这个模型有什么缺点？随后将数据再次输入进去，可能会有一些更新，不停的迭代，我们就可以找到最好的方式，从而使得我们整个系统和方案更加有效。都属于同的场景以及数据的模式和规律，就需要建立一个好的系统，这个系统要有非常完善的非常复杂的ETL管道，通过这些管道数据，来自不同来源的数据，可以按照我们的需求存储，我们可以在一个存储系统中存储，也可以在多个特定目的的存储系统中存储这些数据。比如我们可以使用数据仓库等方式来支持spot的查询，我们可以进行文档的存储，从而支持结构化和半结构化的数据，这些数据可以帮助我们进行文本的分析，还有时间序列的数据库，可以支持物联网世界中自动化的这种需求。我刚才也提到过几次智慧城市中需要对交通进行分析。我们在这个世界中需要很多实时的或者说近实时的流式数据，这些数据它存储的时间比较短，而相应的历史数据可能会存在很长时间，这两种存储方式之间会存在可能的重叠，我们在后期进行数据处理和分析的时候，不希望有过多的数据重叠，因此要找到好的方式消除掉。为此我们要建立不同的数据管道，管道会带来非常高的成本，我们需要有更好的方式来建立文档。为此我们就想建立一种新的方式来进行统一的服务分析，这种方式应该可以处理所有的用例，可以处理来自不同来源的数据，同时也可以应对各种不同的ETL管道，我们需要消除数据的壁垒，消除数据孤岛，同时也要避免数据的重复。为了实现这种简单的统一的数据分析，需要有一个好的平台，我们一直在进行分析，我们发现阿帕奇spark是非常理想的选择，因为它可以用作一种分布式的计算引擎，它已经和数据种种的模式有机的结合，还与机器学习和深度学习的库有非常好的整合，也会支持传统的用户使用sql，这样他们就可以非常方便地开始使用我们新的系统。在我们考虑实时流式传输的时候，也会看一下spark有哪些潜力？实际上spark对于流式传输有非常好的支持和继承。我们还缺一点东西，我们需要统一的存储，统一的存储，应该可以处理不同的场景，比如实时的流式传输，以及近实时的流式传输，时间序列，地理空间位置文档存储，以及面部识别相应的库等等。在我们的想法中，我们需要有这样的方案来支持统一的存储，并且支持所有可能的用例。我们的这种方案应该有一些天生的特点。在在这个方案中以及这个系统中，我们要确保数据是有价值的，是完整的。数据要么存在于系统中，那么不存在于系统中，没有残缺不全的数据提供给用户。我们的系统要支持数据的插入更新以及删除，这听起来非常容易，但是在其之前的存储系统中，包括HDFS S3等等系统中，这些数据都具有不可变的语义数据，加到系统中之后就不可以再进行追加和修改，因此我们需要将这一点改变，我们需要确保用户加入数据之后，还有追加和修改的这种选择。当boss的全文搜索引擎整合到我们的方案中去，他对于文本数据具有非常大的价值。这种属性或者说这种特性叫做data max，是我们重点的特性之一。通过这种方式我们就可以使得文本的搜索更加方便，通过这样的专有的系统，我们对数据进行非常有效的索引，使得全文搜索更加的便捷。carbon data在华为很多生产环境中都有使用。在银行的应用场景中，可以用carbon data来做欺诈检测风险分析，在电信运营商的场景中，可以用于分析用户以及做vip客户的关怀，还可以用于很多场合下的监控功能，我们可以监控某些人员有异常的行为，在互联网的应用场景中可以进行视频门线视频准入的分析，这样非授权人员就不可以进入某一个场合，还可以对于设备尺寸以及分辨率进行分析，对于服务器的负载也可以进行更好的分析。应该是超过10万亿行，接下来我会讲一下对carbon data开源的一些思考。对carbon data进行开源，我们想让carbon data成为一种标准，用于统一的数据格式和数据存储。有很多很多客户，特别是企业客户，比如银行非常害怕技术锁定，不过他们使用非科研的系统，一旦出现什么问题，可能会遭遇到来自技术厂商的技术锁定。他们希望使用开源的系统，这样出问题的时候就非常容易解决，他们也非常方便地从创意的系统迁移到其他系统，这对于他们的数据安全来说是非常重要的。我们希望通过carbon data的开源，建立一个好的生态系统生态系统中，我们和社区一起进步，我们和社区的贡献者，互惠互利的发展，我们可以以提高开放影响力，因为我们可以为开源社区贡献我们的一些经验和代码。与此同时我们可以从开源社区学习到很多很多我们没有的东西，这样我们的开发效率也会提高，通过这样的方式，我们实际上是对开源社区进行了回馈，因为我们之前很多产品中也使用过开源的部件，比如spark和hadoop等等，然后这种方式是非常高效的。我们希望通过这样的方式来拥抱开源文化，使得华为和开源社区中的各位形成双赢的局面。基于这样的原因，我们就决定对carbon data进行开源，在开源的时候我们要选择哪个基金会，选择什么样的社区，我们考虑到阿帕奇和Linux我们觉得其非常适合大数据项目。因为阿帕奇社区中并没有任何的组织隶属关系，这对于社区的发展来说是非常好的。这样可以确保有更多的受众，有更广的参与度。华为不会在社区中去充当老大的位置，每个人都是平等的，整个项目可以更成熟的发展，可以为我们在更大范围内更多场景中满足更多的用例。在选择阿帕奇之后，我们要让我们自己尽快的了解阿帕奇社区的角色，有用户贡献者，代码提交者，项目管理委员会，阿帕奇成员以及阿帕奇的委员会。要了解阿帕奇社区整个文化和工作方式，我们对此是非常认同的，我们可以将文化进行整合，第一点就是以能力和贡献论英雄，你做的越多，你就可以获取越多的东西，对你的认可不是基于你是谁，而是基于你做了什么。刚才谈到了不同的角色，如果你做得很好，你可以成为代码提交者，可以做pmc，还可以进入阿帕奇委员会，如果做到那一步，那你就会非常受欢迎，大家都想和你产生一点联系，想和你打交道，就像特朗普总统他在美国就是香饽饽，很多人都想接近它。它文化第二点就是社区强调社区，而没有组织隶属关系，好的社区可以创造更好的代码，每个人都被担保贡献，那么并不是一两个人写的，而是大家智慧的结晶。通过这样的方式，我们可以使得项目更持久地进行下去，带来更多的价值，而不是一两年就做不下去了。在社区中会有非常多的人才，他们都可以贡献自己的才智，使得项目更安全，项目代码的质量更高。第三点就是共识，决策都是基于共识的，并不是说投票多数人同意就可以做出决策。我们要实现整个社区的共识，我们也不需要独裁者来发布施令，每个人都对于整个项目负责，他们会有一种参与感，会有一种承诺感。这种文化第四点就是尊重开发者，所以开发者都是平等的，不管是比较有经验的开发者还是新手，所有人都是平等的，不会有谁去羞辱谁，每个人的意见都是重要的，都会得到考虑。每个人都有机会学习，每个人都有机会发表自己的意见，他们的意见也会被其他人倾听。接下来这种文化还有一个特点，就是协作开发，所有的讨论都是公开的，在邮件列表中进行讨论，每个人都有公平的发表意见的机会。我们觉得如果很多人都一起来发表自己的意见，最终我们的前进方向应该是不会错的，不同的人从不同的角度来思考同一个问题，这样更可以确保研究的正确性和讨论的正确性，可能会通过这样的方式来确保我们讨论的话题都是重要的，是值得讨论的。这文化还有非常实用的特点，线路图里程碑都是非常透明的，都是所有人共同讨论出来的，一致通过的。不会偏向任何人，所有人都是平等的，做出来的东西是免费使用的，也可以自由的定制化和出售。我们会基于现在已有的知识来做出非常现实的决定，就选择了阿帕奇来作为我们开源的平台。在这个过程中，我们会首先提出倡议，作出决定之后，我们会去看一下哪些人来具体的参与。有些人经过一段时间的参与之后会成为提交者，很多人会在github上有自己的角色，我们会考虑很多问题，包括如何实现自动化的测试，如何做好其他方面的种种工作。我的目标是将我们的项目从孵化阶段逐渐向前推进，从而成为顶级的项目。阿帕奇委员会的相关人员会确保这个过程是顺利的，不会出现大问题。我们在阿帕奇社区中做我们项目的时候会非常小心的去进行相关的活动，会非常有序的去组织，我们要确保版本的发布是及时的，我们要让人们看到我们的项目一直活跃的有人在做，而不是很久都没有什么变化，每个版本的更新都应该是非常有价值的。就像刚才提到的是社区建设的活动，我们需要维持我们在社区中的活跃度，让人们看到我们的项目是非常有价值的，通过这种方式我们可以为开源社区带来更大的贡献。我们的carbon data达到在短时间内迅速成为在全球都非常受欢迎的社区。我们有来自全球很多国家的贡献者，我们的社区中使用英文作为唯一的沟通语言。我们用户来自全球各大洲，我们的邮件列表也非常的活跃，总回复数超过6万，我们的贡献者在很短的时间内就达到了130多名。大家对比一下hbase总共有200名贡献者，hadoop有145名。我希望通过我们的努力来扩大用户数量，我们希望通过每一次的发布，提供更强的功能，更好的性能，使得我们的方案可以覆盖更多的用例。这也就展示了我们的目标，我们希望在不远的将来实现我们的数据地图和mv。更强的性能可以覆盖很多的应用场景，大家看一下，这里有时间序列，还有地理空间，我们希望我们的数据是非常容易维护的，我们希望在内存中实现缓存，还希望能够实现spark data source V2的满足度，或者说符合度，另外我们还需要支持连续的流式传输。在存储方面，我们希望改善云存储性能，还有还要实现更多的编码。在不同的服务中，我们都可以提供相应的数据，比如这些学习人脸识别等等场合，我们都可以使用我们的系统来提供最好的数据和服务。我们这个社区是从2015年开始筹建的，到2016年6月份在阿帕奇上进行孵化，2017年的4月份正式的形成总共有12个稳定的发布版本。在很短的时间内我们就有130多名贡献者，我们微信群里边有400多名活跃的用户，他们为我们的社区献言献策，做出了极大的贡献。最后我要对各位表示感谢，我要说的是，我们的carbon data社区是非常开放的，我们希望吸引到更多新的贡献，我们欢迎任何人为我们带来新的用例，新的设计，新的需求，我们的社区，欢迎各种各样的贡献，包括测试，文档的加强，网站的加强，以及相应的例子的实施和其他引擎的整合等等。好了，谢谢各位。